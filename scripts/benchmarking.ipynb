{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "65e1d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to see if models are capable of counting task \n",
    "# w/ performance > random chance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.evals import load_model, create_counting_prompt\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d2d7b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSISTENT_MODEL_DIR = \"/workspace/models/\"\n",
    "DATA_DIR = \"/workspace/data/synthetic-data-1.json\"\n",
    "MODEL_PREFIX = [\n",
    "    'Qwen3-1.7B',\n",
    "    'Qwen3-4B',\n",
    "    'Qwen3-8B',\n",
    "    'Qwen3-14B',\n",
    "    'Phi-3-mini-4k-instruct' # ideally, we'll later use this to check for generality\n",
    "][1]\n",
    "\n",
    "# import benchmarking dataset \n",
    "count_df = pd.read_json(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a582d449",
   "metadata": {},
   "source": [
    "# Formatting \n",
    "Get test data into appropriate form, including instruct formatting. \n",
    "\n",
    "Create a torch dataset to hold all test examples + use dataloader or efficient batched inference during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9a8b1a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61978a4b8ad841dfa156b9cf97de847a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer, model = load_model(PERSISTENT_MODEL_DIR + MODEL_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4d1704a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_ix</th>\n",
       "      <th>category</th>\n",
       "      <th>list_length</th>\n",
       "      <th>clean_list</th>\n",
       "      <th>clean_category_indices</th>\n",
       "      <th>clean_category_count</th>\n",
       "      <th>corrupt_list</th>\n",
       "      <th>corrupt_category_indices</th>\n",
       "      <th>corrupt_category_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>colors</td>\n",
       "      <td>3</td>\n",
       "      <td>[red, banana, computer]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[apple, banana, computer]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>3</td>\n",
       "      <td>[car, bus, banana]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>2</td>\n",
       "      <td>[apple, bus, banana]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>shapes</td>\n",
       "      <td>3</td>\n",
       "      <td>[square, circle, triangle]</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>[square, apple, triangle]</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>continents</td>\n",
       "      <td>3</td>\n",
       "      <td>[computer, asia, apple]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[computer, banana, apple]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>metals</td>\n",
       "      <td>3</td>\n",
       "      <td>[banana, gold, silver]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>[banana, apple, silver]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>44</td>\n",
       "      <td>street_signs</td>\n",
       "      <td>7</td>\n",
       "      <td>[rose, car, yield, speed, apple, stop, pedestr...</td>\n",
       "      <td>[2, 3, 5, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>[rose, car, yield, speed, apple, dog, pedestrian]</td>\n",
       "      <td>[2, 3, 6]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>45</td>\n",
       "      <td>continents</td>\n",
       "      <td>7</td>\n",
       "      <td>[asia, dog, africa, europe, apple, antarctica,...</td>\n",
       "      <td>[0, 2, 3, 5, 6]</td>\n",
       "      <td>5</td>\n",
       "      <td>[asia, dog, africa, europe, apple, car, americas]</td>\n",
       "      <td>[0, 2, 3, 6]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>46</td>\n",
       "      <td>time_units</td>\n",
       "      <td>7</td>\n",
       "      <td>[second, year, car, day, month, minute, hour]</td>\n",
       "      <td>[0, 1, 3, 4, 5, 6]</td>\n",
       "      <td>6</td>\n",
       "      <td>[apple, year, car, day, month, minute, hour]</td>\n",
       "      <td>[1, 3, 4, 5, 6]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>47</td>\n",
       "      <td>elements</td>\n",
       "      <td>7</td>\n",
       "      <td>[hydrogen, carbon, gold, silver, helium, oxyge...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>7</td>\n",
       "      <td>[hydrogen, apple, gold, silver, helium, oxygen...</td>\n",
       "      <td>[0, 2, 3, 4, 5, 6]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>48</td>\n",
       "      <td>shapes</td>\n",
       "      <td>7</td>\n",
       "      <td>[apple, car, dog, rose, chair, circle, house]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>1</td>\n",
       "      <td>[apple, car, dog, rose, chair, table, house]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4989 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_ix      category  list_length  \\\n",
       "0             0        colors            3   \n",
       "1             1      vehicles            3   \n",
       "2             2        shapes            3   \n",
       "3             3    continents            3   \n",
       "4             4        metals            3   \n",
       "...         ...           ...          ...   \n",
       "4984         44  street_signs            7   \n",
       "4985         45    continents            7   \n",
       "4986         46    time_units            7   \n",
       "4987         47      elements            7   \n",
       "4988         48        shapes            7   \n",
       "\n",
       "                                             clean_list  \\\n",
       "0                               [red, banana, computer]   \n",
       "1                                    [car, bus, banana]   \n",
       "2                            [square, circle, triangle]   \n",
       "3                               [computer, asia, apple]   \n",
       "4                                [banana, gold, silver]   \n",
       "...                                                 ...   \n",
       "4984  [rose, car, yield, speed, apple, stop, pedestr...   \n",
       "4985  [asia, dog, africa, europe, apple, antarctica,...   \n",
       "4986      [second, year, car, day, month, minute, hour]   \n",
       "4987  [hydrogen, carbon, gold, silver, helium, oxyge...   \n",
       "4988      [apple, car, dog, rose, chair, circle, house]   \n",
       "\n",
       "     clean_category_indices  clean_category_count  \\\n",
       "0                       [0]                     1   \n",
       "1                    [0, 1]                     2   \n",
       "2                 [0, 1, 2]                     3   \n",
       "3                       [1]                     1   \n",
       "4                    [1, 2]                     2   \n",
       "...                     ...                   ...   \n",
       "4984           [2, 3, 5, 6]                     4   \n",
       "4985        [0, 2, 3, 5, 6]                     5   \n",
       "4986     [0, 1, 3, 4, 5, 6]                     6   \n",
       "4987  [0, 1, 2, 3, 4, 5, 6]                     7   \n",
       "4988                    [5]                     1   \n",
       "\n",
       "                                           corrupt_list  \\\n",
       "0                             [apple, banana, computer]   \n",
       "1                                  [apple, bus, banana]   \n",
       "2                             [square, apple, triangle]   \n",
       "3                             [computer, banana, apple]   \n",
       "4                               [banana, apple, silver]   \n",
       "...                                                 ...   \n",
       "4984  [rose, car, yield, speed, apple, dog, pedestrian]   \n",
       "4985  [asia, dog, africa, europe, apple, car, americas]   \n",
       "4986       [apple, year, car, day, month, minute, hour]   \n",
       "4987  [hydrogen, apple, gold, silver, helium, oxygen...   \n",
       "4988       [apple, car, dog, rose, chair, table, house]   \n",
       "\n",
       "     corrupt_category_indices  corrupt_category_count  \n",
       "0                          []                       0  \n",
       "1                         [1]                       1  \n",
       "2                      [0, 2]                       2  \n",
       "3                          []                       0  \n",
       "4                         [2]                       1  \n",
       "...                       ...                     ...  \n",
       "4984                [2, 3, 6]                       3  \n",
       "4985             [0, 2, 3, 6]                       4  \n",
       "4986          [1, 3, 4, 5, 6]                       5  \n",
       "4987       [0, 2, 3, 4, 5, 6]                       6  \n",
       "4988                       []                       0  \n",
       "\n",
       "[4989 rows x 9 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5133a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df['clean_list_string'] = [' '.join(ele) for ele in count_df['clean_list']]\n",
    "\n",
    "count_df['prompt'] = count_df.apply(\n",
    "    lambda row: create_counting_prompt(\n",
    "        entity_type = row['category'],\n",
    "        word_list = row['clean_list_string'],\n",
    "        tokenizer = tokenizer\n",
    "    ), axis = 1\n",
    ")\n",
    "\n",
    "# pprint(count_df['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d4fd4316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(75)\n"
     ]
    }
   ],
   "source": [
    "# load dataset into a dataloader â€“ this will help handle batching\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sample_index, tokenized_prompts):\n",
    "        self.sample_index = sample_index\n",
    "        self.input_ids = tokenized_prompts['input_ids']\n",
    "        self.attention_mask = tokenized_prompts['attention_mask']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'sample_index': self.sample_index[idx],\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx]\n",
    "        }\n",
    "\n",
    "# we're tokenizing everything here, but the dataloader will handle batching later :) \"tokenizing is very cheap\"\n",
    "tokenized_prompts = tokenizer(count_df['prompt'].tolist(), add_special_tokens = False, max_length = 100, padding = 'max_length', truncation = True, return_tensors = 'pt')\n",
    "print(tokenized_prompts['attention_mask'].sum(dim = 1).max()) # Must be under max length to confirm nothing was truncated (since attention mask applies a 1 to indicate \"some guy was here\")\n",
    "\n",
    "count_dl = DataLoader(TextDataset(\n",
    "    count_df['sample_ix'].tolist(),\n",
    "    tokenized_prompts # don't move to gpu yet (or will have big mem problems)\n",
    "), batch_size = 4, shuffle = False)\n",
    "\n",
    "# pprint(next(iter(count_dl)), width = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a5add",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b646c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1248/1248 [03:16<00:00,  6.35it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 1 \n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(count_dl, total = len(count_dl)):\n",
    "        sample_ix = batch[\"sample_index\"]\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attn_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        probs = model(input_ids, attention_mask=attn_mask).logits.softmax(-1)\n",
    "\n",
    "        last_pos = attn_mask.sum(1) - 1\n",
    "        b_idx = torch.arange(input_ids.size(0), device = device)\n",
    "\n",
    "        tok_ids = input_ids[b_idx, last_pos]\n",
    "        tok_probs = probs[b_idx, last_pos, :]\n",
    "\n",
    "        \n",
    "        topk_probs, topk_idx = torch.topk(tok_probs, k = k, dim = 1)\n",
    "        tokens_flat = tokenizer.convert_ids_to_tokens(topk_idx.cpu().flatten().tolist())\n",
    "        topk_tokens = [tokens_flat[i * k:(i + 1) * k] for i in range(len(tokens_flat) // k)]\n",
    "\n",
    "        for s_ix, toks, ps in zip(sample_ix.tolist(), topk_tokens, topk_probs.cpu()):\n",
    "            results.append(\n",
    "                {\n",
    "                    \"sample_ix\": s_ix,\n",
    "                    \"output_token\": toks[0], # this code only supports k = 1 for now            \n",
    "                    \"output_prob\": ps.tolist()[0]\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ea65477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "\n",
    "# join with the original dataframe to get accuracy \n",
    "combined = pd.merge(results, count_df, on = 'sample_ix', how = 'inner')\n",
    "\n",
    "# identify the # correct \n",
    "combined['is_correct'] = np.where(combined['output_token'] == combined['clean_category_count'], 1, 0)\n",
    "\n",
    "# # filter for rows where is_correct = 1 â€“ oh boy it never gets this right for 1.7\n",
    "# combined.query(\"is_correct == 1\")\n",
    "# combined['is_correct'].unique()\n",
    "\n",
    "# formatting accuracy (is answer returned as int)\n",
    "combined[\"guess_int\"] = pd.to_numeric(combined[\"output_token\"], errors = \"coerce\")\n",
    "combined[\"is_integer\"]  = combined[\"guess_int\"].notna()\n",
    "\n",
    "# plausible counts (â‰¤ list length)\n",
    "combined[\"is_plausible\"] = combined[\"is_integer\"] & (\n",
    "    combined[\"guess_int\"] <= combined[\"list_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7a7dc7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                    Qwen3-4B\n",
       "params                   4.022468\n",
       "total_rows                 497833\n",
       "total_correct                   0\n",
       "accuracy                      0.0\n",
       "chance_accuracy          0.210803\n",
       "accuracy_above_chance   -0.210803\n",
       "pct_integer                   1.0\n",
       "pct_plausible            0.946084\n",
       "acc_on_plausible              0.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  accuracy metrics \n",
    "# todo: want to check accuracy for count + instruction following (does it output what we expect) â€“ generally answer format following seems to be pretty good (even w/ 1.7B)\n",
    "# todo: also want to check answer plausibility (basically, does the model say \"4\" when the full list is only 3)\n",
    "# chance accuracy is expected prob. of a uniform random guess \n",
    "# being correct, averaged over dataset (since lists are of varying lengths)\n",
    "n_rows = len(combined)\n",
    "n_correct = combined['is_correct'].sum()\n",
    "\n",
    "# overall accuracy \n",
    "acc = combined['is_correct'].mean()\n",
    "\n",
    "# expected accuracy under a uniform random guess\n",
    "chance = (1/combined['list_length']).mean()\n",
    "accuracy_above_chance = acc - chance \n",
    "\n",
    "pct_integer = combined[\"is_integer\"].mean()\n",
    "pct_plausible = combined[\"is_plausible\"].mean()\n",
    "acc_on_plausible = combined.loc[combined[\"is_plausible\"],\n",
    "                                   \"is_correct\"].mean()\n",
    "\n",
    "# param count \n",
    "params = list(model.parameters())\n",
    "total = sum(p.numel() for p in params)\n",
    "                                \n",
    "\n",
    "metrics = pd.Series({\n",
    "    'model': MODEL_PREFIX,\n",
    "    'params': total/1e9, # in billions\n",
    "    'total_rows': n_rows,\n",
    "    'total_correct': n_correct,\n",
    "    'accuracy': acc,\n",
    "    'chance_accuracy': chance,\n",
    "    'accuracy_above_chance': accuracy_above_chance,\n",
    "    'pct_integer': pct_integer, # correct format\n",
    "    'pct_plausible': pct_plausible, # % of rows where guess was â‰¤ total list length\n",
    "    'acc_on_plausible': acc_on_plausible\n",
    "})\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ac532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data for test results + agg. metrics \n",
    "combined.to_csv(f\"/workspace/data/results_{MODEL_PREFIX}.csv\", index = False)\n",
    "metrics.to_csv(f\"/workspace/data/agg_metrics_{MODEL_PREFIX}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7f7fb924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove model object from environment after benchmarking is complete \n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489906f",
   "metadata": {},
   "source": [
    "## Plot \n",
    "dims of interest: correct length, total length, accuracy â€“ also want to see how performance changes across model sizes.\n",
    "\n",
    "1. Model size (params) v. accuracy \n",
    "2. Total length, accuracy (check to see how accuracy changes as list length changes)\n",
    "3. Correct length (x), total length (y) â€“ a heatmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b7f1a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
